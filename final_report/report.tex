\documentclass{article}
\usepackage[margin=1.5in, includeheadfoot]{geometry}
\usepackage{biblatex-chicago}
\usepackage{fancyhdr}
\usepackage[fleqn]{amsmath}
\usepackage{amssymb, amsthm}
\usepackage{microtype}
\usepackage[shortlabels]{enumitem}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage[]{float}
\usepackage{graphicx}
\usepackage{subfig}
\usepackage{hyperref}
\graphicspath{ {./images/} }

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
\lstdefinestyle{mystyle}{
    % backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    % numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}
\lstset{style=mystyle}

\linespread{1.2}

\author{Gus Beringer}
\title{Capstone Project Draft}

\date{\today}
\newtheorem{theorem}{Theorem}
\def\D{\mathbb{D}}
\def\I{\mathbb{I}}
\def\N{\mathbb{N}}
\def\R{\mathbb{R}}
\def\T{\mathbb{T}}
\def\U{\mathbb{U}}
\def\Z{\mathbb{Z}}
\def\vep{{\varepsilon}}



\begin{document}
\maketitle
\tableofcontents

\section{Introduction}

Every Wikipedia article contains links to other articles. If the article references a concept that is also another Wikipedia article, the text can link to that article.
The Wikipedia hyperlink graph is the graph with every article as a vertex. The edges between the vertices are the links between the articles.

It is observable that the Wikipedia hyperlink graph is a small world network.
A small-world network is a graph where each vertex is connected to few vertices, but can reach all other vertices within a few steps.

An undirected graph is connected when there is a path between any two vertices in the graph.
If there is a path between any two vertices in a directed graph, it is a strongly connected.
If a directed graph has an undirected graph that is connected, it is weakly connected.

% TODO: define adjacency matrix.


\section{Sparse Adjacency Matrices}

The Wikipedia hyperlink graph has 6,102,910 vertices, which creates challenges for representing the graph in a program.
If we create an entry for every number in the adjacency matrix of $n$ nodes, that is a dense matrix, the program requires $n^2$ space in total.  
For the wikipedia hyperlink graph, that's over $3.7 * 10^{13}$ entries.
However, most of the numbers in the adjacency matrix are zero, so can store the matrix more efficiently by only keeping track of non-zero entries.

The compressed sparse row (CSR) format is the most popular sparse matrix format.
We outline the \textbf{scipy} implementation of the CSR format.
There are three arrays that are used to represent the matrix, \textbf{data}, \textbf{indices}, and \textbf{data}.
\autocite{scipy_doc}
The \textbf{data} array contains the values for the non-zero elements in the order they appear in the matrix row by row.
The \textbf{indices} array contains the index of the column for each non-zero element.
The \textbf{indptr} array maps the matrix values to the rows in the matrix.
For an $m\times n$ matrix, the \textbf{indptr} array contains $m+1$ elements, where the first entry is always 0.

To extract the values of an arbitrary row $i$, we set $s = \textbf{indptr}[i]$ and $t = \textbf{indptr}[i+1]$. Then, the values of the items at row $i$ are $\textbf{data}[s:t]$ with columns corresponding to the array $\textbf{indices}[s:t]$. 

We provide an example of the format with the following matrix,
\begin{equation*}
    \begin{pmatrix}
        52 & 0  & 0  & 0  \\
        0  & 0  & 43 & 0  \\
        67 & 0  & 0  & 81  \\
        0  & 20 & 0  & 0  \\
    \end{pmatrix}.
\end{equation*}
Then, \textbf{data} = $[52, 43, 67, 81, 20]$, \textbf{indices} = $[0, 2, 0, 3, 1]$, and \textbf{indptr} = $[0, 1, 2, 4, 5]$. The number $52$ appears first in the matrix in the 0th column, so \textbf{data}$[0] = 52$ and \textbf{indices}$[0] = 0$.

In this example, the gains of using a sparse matrix are minimal. Instead of 16 entries, the matrix is represented with 15 entries. However, when there are far more zeroes than non-zero elements, the sparse format is far smaller.


\section{Degree Distribution}

The degree of a node in an undirected graph is the number of edges connecting that node. For a directed graph we need to distinguish between the edges leaving and entering the node. 
The outdegree of a node is the number of edges leave from that node.
The indegree of a node in a directed graph is the number of edges that enter that node from another node.

We describe the distribution of nodes in the Wikipedia hyperlink graph.
The indegree distribution has a smooth exponential descent, while the outdegree distribution grows sharply before descending. 
Most of the network has a small indegree. We find that 93.84\% of the network has a indegree smaller than 300. However, there are still plenty of nodes with large indegree. We find 1,468 of vertices in the network with indegree larger than 10,000.

The outdegree distribution has a much smaller maximum of 11,897 vertices. This is because the outdegree is limited by the size of the article, but the indegree is only limited by the size of the graph.


\begin{figure}[H]
    \centering
    \caption[]{Degree Statistics}
    \begin{tabular}{lrrrrr}
        \toprule
        & Q1 & Median & Mean & Q3 & Maximum\\
        \midrule
        Outdegree & 4 & 19 & 91.46176 & 81 & 1,305,902\\
        Indegree & 17 & 39 & 91.46176 & 107 & 11,897\\
        \bottomrule
    \end{tabular}
\end{figure}

\begin{figure}[H]
    \centering
    \parbox{6cm}{
    \includegraphics[width=6cm]{in_degree_dist}
    \caption{Indegree Distribution}
    \label{fig:2figsA}}
    \qquad
    \begin{minipage}{6cm}
    \includegraphics[width=6cm]{out_degree_dist}
    \caption{Outdegree Distribution}
    \label{fig:2figsB}
    \end{minipage}
\end{figure}


\section{Centrality}

There are millions of nodes in the Wikipedia network, but not all of them are important.
The centrality measures provide methods of ranking nodes based on different measures of importance.
We evaluate and compare three different centrality metrics in the Wikipedia hyperlink graph.

\subsection{Degree Centrality}

Degree centrality is one of the simplest forms of centrality.

To compute the indegree and outdegree we simply sum the rows and columns of the adjacency matrix.

\subsubsection{Results}
\begin{figure}[H]
    \centering
    \caption{Highest Indegree}
    \begin{tabular}{llr}
        \toprule
        Article ID & Title & In Degree\\
        \midrule
        14919 & International\_Standard\_Book\_Number & 1305902\\
        48361 & Geographic\_coordinate\_system & 1151082\\
        25175562 & Virtual\_International\_Authority\_File & 904960\\
        18852926 & International\_Standard\_Name\_Identifier & 525539\\
        422994 & Digital\_object\_identifier & 471024\\
        \addlinespace
        3434750 & United\_States & 440874\\
        35412202 & Wikidata & 438109\\
        30463 & Taxonomy\_(biology) & 432978\\
        23538754 & Wayback\_Machine & 411661\\
        30890 & Time\_zone & 406023\\
        \addlinespace
        2987862 & Global\_Biodiversity\_Information\_Facility & 388044\\
        2855554 & IMDb & 339971\\
        39736 & Binomial\_nomenclature & 334349\\
        11039790 & Animal & 332711\\
        8439 & Diacritic & 322697\\
        \bottomrule
    \end{tabular}
\end{figure}
    
There are several pages in the Wikipedia network with excessive indegree compared to their outdegree. 
The article \textbf{International\_Standard\_Book\_Number} has an indegree of 1,322,167, but only an outdegree of 559. In fact, 20\% of all vertices in the graph have an edge connecting towards \textbf{International\_Standard\_Book\_Number}.
% This is because any article with a book in the references will contain a link to that article.
This is because of the automatic linking from references.
Any article with a citation that has an ISBN identifier will link to the page \textbf{International\_Standard\_Book\_Number}.
For similar reasons, the articles \textbf{Wayback\_Machine} and \textbf{OCLC} all have all have excessive indegree compared to their outdegree.



\subsection{Closeness Centrality}


The motivation for closeness centrality is to find the nodes that are closest to the other nodes in the network.

We are given a directed graph $G(V,E)$ with $n$ nodes and $m$ edges.
A directed graph is strongly connected if there is path between any two vertices. We assume that $G$ is strongly connected.
The distance $d(u, v)$ between vertices $u$ and $v$ is the shortest possible path between the vertices. Since $G$ is strongly connected, $d(u, v)$ always exists.


% Given a graph $G(V, E)$, the distance $d(u, v)$ between  vertices 
Eppstein defines closeness centrality $c_v$ of a vertex $v$ as,
\begin{equation*}
    c_v = \frac{n-1}{\sum_{u \in V}d(u,v)}
\end{equation*} 
The numerator $n-1$ normalizes the measure, making it comparable across different graphs.


The single source shortest path problem involves finding the distance from a single source to all other nodes in the graph. For undirected graphs, 
The all pairs shortest path problem is to find the shortest path between all possible pairs of vertices in the graph.
To find the exact closeness centrality for all nodes in the network, we must solve the all pairs shortest path problem. However, for large networks this is extremely computationally intensive. 
Eppstein provides a near-linear time approximation for centrality when the diameter is $O(\log n)$. That is, when the graph is a small world network. Since the Wikipedia hyperlink graph is a small world network, this algorithm is a good fit.

Then Eppstein presents the following algorithm RAND for computing closeness centrality,
\begin{enumerate}[1.]
    \item 
    Let k be the number of iterations needed to obtain the desired error bound.

    \item
    In iteration $i$, pick vertex $v_i$ uniformly at random from $G$ and solve the single source shortest path problem with $v_i$ as the source.

    \item 
    Let
    \begin{equation*}
        \hat{c}_ua = \frac{1}{\sum^k_{i=1} \frac{n d(v_i, u)}{k(n-1)}}
    \end{equation*}
    be the centrality estimator for vertex $u$.
\end{enumerate}

Since the graph is unweighted, we use a breadth first search to solve the SSSP problem.

\subsubsection{Results}

\begin{figure}[H]
    \caption[fig]{Closeness Centrality}
    \centering
    \begin{tabular}{rlr}
        \toprule
        Article ID & Title & Centrality \\
        \midrule
        14919 & International\_Standard\_Book\_Number & 0.5357142\\
        32927 & World\_War\_II & 0.5357142\\
        3434750 & United\_States & 0.5172413\\
        5843419 & France & 0.5172413\\
        23538754 & Wayback\_Machine & 0.5172413\\
        \addlinespace
        11867 & Germany & 0.4999999\\
        14532 & Italy & 0.4999999\\
        25391 & Russia & 0.4999999\\
        48361 & Geographic\_coordinate\_system & 0.4999999\\
        422994 & Digital\_object\_identifier & 0.4999999\\
        \addlinespace
        1057428 & Typographical\_error & 0.4999999\\
        26748 & Switzerland & 0.4838709\\
        31717 & United\_Kingdom & 0.4838709\\
        883885 & OCLC & 0.4838709\\
        5042916 & Canada & 0.4838709\\
    \bottomrule
\end{tabular}
\end{figure}

The World War II article is the only topic so far that is not a reference vertex or a country that has a high centrality. The importance of World War II within Wikipedia is not surprising. An unofficial Wikipedia game developed around 2010 called Clicks to Hitler, in which the participants try to reach the aforementioned page as quickly as possible.
\autocite{cornell}
Most articles link to at least one country, and most countries link to the World War II article.
% https://blogs.cornell.edu/info2040/2019/10/23/the-significance-of-hitlers-wikipedia-page/

\subsection{Katz Centrality}

The Katz Centrality measure was introduced in 1953 by Leo Katz.
\autocite{katz1953}
In this measure of centrality, the weighted count of incoming paths to each node determines it's importance in the network. The attenuation factor $\alpha$ changes how quickly the weights decrease the importance of walks.

We define Katz Centrality as,
\begin{equation*}
    C_{\textrm{Katz}}(i) = \sum_{j} (I_{ij} + \alpha A_{ij} + \alpha^2 A_{ij}^2 + \alpha^3 A_{ij}^3 + \dots).
\end{equation*}
\autocite{katz2011}

Then,
\begin{align*}
    C_{\textrm{Katz}} &= (I + \alpha A + \alpha^2 A^2 + \alpha^3 A^3 + \dots) \overrightarrow{1}\\
    &= \sum^\infty_{n=1} (\alpha^n A^n)\overrightarrow{1} \\ 
&= (I - \alpha A)^{-1} \overrightarrow{1} 
\end{align*}
% https://www.youtube.com/watch?v=DfV-pjRTlLg

To ensure that $C_{\textrm{Katz}}$ exists, we must choose an attenuation factor $\alpha$ such that the matrix $I - \alpha A$ is invertible. The matrix $I - \alpha A$ is non-invertible when,
\begin{align*}
    & \det (I - \alpha A) = 0 \\
    \implies \; & \det (A - \frac{1}{\alpha} I) = 0.
\end{align*}
This is simply the characteristic equation of $A$. Hence, we must find eigenvalues that satisfy the equation $\det(A - \lambda I)$, where $\lambda = \frac{1}{\alpha}$. Then, $\alpha = \frac{1}{\lambda}$.

Let $\lambda_1, \lambda_2, \dots, \lambda_n$ be the eigenvalues of $A$. We set $\alpha < \frac{1}{\max(\lambda_1, \dots, \lambda_n)}$.
Then, $\max(\lambda_1, \dots, \lambda_n) < \frac{1}{\alpha}$. Thus, $I - \alpha A$ is invertible.

% https://www.math.fsu.edu/~bertram/lectures/Centrality.pdf


With extremely large matrices the inverse is difficult and imprecise to compute directly with a runtime of $O(n^3)$.
Therefore, we use power iteration to compute the measure instead.

We have,
\begin{align*}
    & C_{\textrm{Katz}} = (I - \alpha A)^{-1} \overrightarrow{1} \\
    \implies & (I - \alpha A) C_{\textrm{Katz}} = \overrightarrow{1} \\
    \implies & C_{\textrm{Katz}} = \alpha A C_{\textrm{Katz}} + \overrightarrow{1}
\end{align*}
We then define the following recurrence relation,
\begin{align*}
    x_k = \alpha A x_{k+1} + \overrightarrow{1}
\end{align*} where the $x_k$ is an approximation of $C_{\textrm{Katz}}$. We then iterate until the norm of $x_{k} - x_{k-1}$ reaches a desired error.

\subsubsection{Results}
\begin{figure}[H]
    \centering
    \caption{Katz Centrality Results}
    \begin{tabular}{llr}
        \toprule
        Article ID & Title & Katz Centrality\\
        \midrule
        14919 & International\_Standard\_Book\_Number & 0.0864162\\
        422994 & Digital\_object\_identifier & 0.0549040\\
        48361 & Geographic\_coordinate\_system & 0.0511208\\
        25175562 & Virtual\_International\_Authority\_File & 0.0387391\\
    23538754 & Wayback\_Machine & 0.0342068\\
    \addlinespace
    234930 & International\_Standard\_Serial\_Number & 0.0341706\\
    30890 & Time\_zone & 0.0285691\\
    5843419 & France & 0.0271659\\
    3434750 & United\_States & 0.0267877\\
    35412202 & Wikidata & 0.0253573\\
    \addlinespace
    48455863 & Semantic\_Scholar & 0.0251241\\
    503009 & PubMed & 0.0229752\\
    47548 & Daylight\_saving\_time & 0.0222805\\
    30463 & Taxonomy\_(biology) & 0.0222407\\
    19828134 & Plant & 0.0219509\\
    \bottomrule
    \end{tabular}
\end{figure}

We see that high degree nodes dominate in Katz Centrality.
The top five nodes that are listed all have very high indegree.
The majority of the highest scoring vertices seem to be reference nodes, such as \textbf{International\_Standard\_Serial\_Number}, \textbf{Virtual\_International Authority\_File}, and \textbf{PubMed}.
The only exceptions are the two country articles, \textbf{United\_States} and \textbf{France}.

% \subsection{Comparing Measures}

% The Katz centrality and indegree centrality metrics both emphasize the importance of many citations from other articles. However, the centrality 


\section{Graph Radius \& Diameter}

The eccentricity of a vertex $v_i$ is the greatest distance between any other vertex $v$. That is, $e(v_i) = \max d(v_i, v)_{v \in V}$.

The radius of a graph is the minimum eccentricity of the entire graph, while the diameter of a graph is the maximum eccentricity.


Mathematically,
\begin{align*}
    r = \min e(v)_{v \in V} \\
    d = \max e(v)_{v \in V}
\end{align*}
where $r$ is the radius and $d$ is the diameter.

In the Wikipedia hyperlink graph the diameter can be conceptualized as given any article, how what is the maximum number of clicks to any other article in a shortest path. The radius can similarly be conceptualized as the minimum number of clicks to any other articles in a shortest path.


A naïve method of estimating the radius and the diameter is running multiple breadth first searches from random nodes and returning the minimum and maximum of the result. Boitmanis et. al presents a better approximation algorithm.
\autocite{boitmanis}
% https://sci-hub.se/https://dl.acm.org/doi/10.1007/11764298_9
Instead of starting the breadth first search from a uniformly random node, we start the breadth first search from the node furthest from the set of already processed nodes. This can be done in $O(n)$ time by keeping track of the results each breadth first search.

Using this search we can identify a tunnel of articles, from "Billboard Top Rock'n'Roll Hits: 1972" to "Billboard Top Hits: 1995". Where only a single path with 23 articles exists between the two articles.


\subsection{Results}

We estimate the radius and diameter of the 94.7\% of vertices that are strongly connected.
Using 20 iterations, the radius and diameter are both estimated at 33. That is, the eccentricity of the 20 tested nodes are all 33.
It is not clear if the estimated radius and diameter corresponds to the actual radius and diameter.
If the estimation is accurate, then from any article, the rest of the cluster is at most 33 clicks away.
This measure is robust to change against removing nodes.

Removing the first 10,000 vertices with the highest indegree results in no change to the estimated radius and diameter. 
With 20 iterations, all the tested eccentricities are still 33. This means that there are many different shortest paths between any two nodes in the network. When one node in the path is removed, there are still many paths available.

\section{Further Research}

One property of the hyperlink graph that isn't explored here is the order of the links. It is observable that repeatedly clicking the first link in nearly all articles will eventually lead to the Philosophy article. This is likely due to the definitional nature of the first paragraph in the article, that the first link in the article further abstracts the page.

% \subsection*{}

\printbibliography

\end{document}